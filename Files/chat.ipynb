{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from langchain_chroma import Chroma # Vector database for embeddings\n",
    "from langchain_openai import ChatOpenAI # Chat model\n",
    "from langchain_community.document_loaders import TextLoader # Document loading\n",
    "from langchain.text_splitter import CharacterTextSplitter # Document chunking\n",
    "from langchain_openai import OpenAIEmbeddings # Embedding model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "# APIs\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "print(api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load th PDF\n",
    "from langchain_community.document_loaders import PyMuPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Adobe PDF Library 9.0', 'creator': 'Adobe InDesign CS4 (6.0.6)', 'creationdate': '2023-07-13T16:47:13+01:00', 'source': '/home/anudeep/Desktop/gen ai/pdf/Medical_document.pdf', 'file_path': '/home/anudeep/Desktop/gen ai/pdf/Medical_document.pdf', 'total_pages': 248, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-07-14T11:35:59+02:00', 'trapped': '', 'modDate': \"D:20230714113559+02'00'\", 'creationDate': \"D:20230713164713+01'00'\", 'page': 0}, page_content='Vol. 25  No. 2  2023\\nHealth Systems in Transition\\nApproaches to data linkage \\nfor evidence-informed policy \\nHealth and Care Data\\nDimitra Panteli, Katherine Polin, \\nErin Webb, Sara Allin, Andrew Barnes, \\nAlexander Degelsegger-Márquez, \\nSaira Ghafur, Margaret Jamieson, \\nYoon Kim, Yulia Litvinova, \\nUlrike Nimptsch, Maari Parkkinen, \\nTrine Aagren Rasmussen, \\nChristoph Reichebner, Julia Röttger, \\nJuliet Rumball-Smith, Giada Scarpetti, \\nAnna Lene Seidler, Johanna Seppänen, \\nMerran Smith, Morgan Snell, Dalibor \\nStanimirovic, Robert Verheij, Metka \\nZaletel, Reinhard Busse')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyMuPDFLoader(\"/home/anudeep/Desktop/gen ai/pdf/Medical_document.pdf\")\n",
    "data = loader.load()\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "762"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Adobe PDF Library 9.0', 'creator': 'Adobe InDesign CS4 (6.0.6)', 'creationdate': '2023-07-13T16:47:13+01:00', 'source': '/home/anudeep/Desktop/gen ai/pdf/Medical_document.pdf', 'file_path': '/home/anudeep/Desktop/gen ai/pdf/Medical_document.pdf', 'total_pages': 248, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-07-14T11:35:59+02:00', 'trapped': '', 'modDate': \"D:20230714113559+02'00'\", 'creationDate': \"D:20230713164713+01'00'\", 'page': 1}, page_content='Carlos Alvarez-Dardet Díaz, University of Alicante, Spain\\nRifat Atun, Harvard University, United States\\nArmin Fidler, Management Center Innsbruck\\nColleen Flood, University of Toronto, Canada\\nPéter Gaál, Semmelweis University, Hungary\\nUnto Häkkinen, National Institute for Health and Welfare, Finland\\nWilliam Hsiao, Harvard University, United States\\nAllan Krasnik, University of Copenhagen, Denmark\\nJoseph Kutzin, World Health Organization\\nSoonman Kwon, Seoul National University, Republic of Korea\\nJohn Lavis, McMaster University, Canada\\nVivien Lin, La Trobe University, Australia\\nGreg Marchildon, University of Regina, Canada\\nNata Menabde, World Health Organization\\nCharles Normand, University of Dublin, Ireland\\nRobin Osborn, The Commonwealth Fund, United States\\nDominique Polton, National Health Insurance Fund for Salaried Staff (CNAMTS), France\\nSophia Schlette, Federal Statutory Health Insurance Physicians Association, Germany\\nIgor Sheiman, Higher School of Economics, Russian Federation')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_175913/1053846224.py:7: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "# Create DB\n",
    "# Embed and store the texts\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "persist_directory = 'db'\n",
    "\n",
    "## here we are using OpenAI embeddings but in future we will swap out to local embeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=texts,     # Creates a new vector DB from a list of documents\n",
    "                                 embedding=embedding,\n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can load the persisted database from disk, and use it as normal. \n",
    "vectordb = Chroma(persist_directory=persist_directory,  # Loads an existing vector DB (or creates an empty persistent one)\n",
    "                  embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a retriever\n",
    "retriever = vectordb.as_retriever() # This converts your Chroma vector store (which stores your documents as embeddings) into a retriever object.\n",
    "docs = retriever.get_relevant_documents(\"Explain Methodological approach\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'similarity'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})\n",
    "retriever.search_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': 2}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.search_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a chain\n",
    "# create the chain to answer questions \n",
    "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(), \n",
    "                                  chain_type=\"stuff\",  # Simply \"stuff\" (concatenate) all the retrieved documents into a \n",
    "                                  retriever=retriever, # single prompt and pass that whole thing to the language model.\n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "# The function process_llm_response() takes the output \n",
    "# from a RetrievalQA chain (like from LangChain), prints the final answer, and then lists the sources (documents) that the answer came from.\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The methodological approach of this review is to analyze and distill information from existing practices and evidence in Europe and other countries regarding the secondary use of data for policy-making. This approach is different from comparative studies of healthcare systems and instead focuses on providing insights for policymakers. The review also considers the organizational design and structure of service provision, as well as data accessibility and regulation, in order to understand the development and linkage of relevant databases. Additionally, the review examines application procedures and provides an overview of research conducted using the available data.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/home/anudeep/Desktop/gen ai/pdf/Medical_document.pdf\n",
      "/home/anudeep/Desktop/gen ai/pdf/Medical_document.pdf\n"
     ]
    }
   ],
   "source": [
    "# full example\n",
    "query = \"Explain Methodological approach\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
